#!/bin/bash

set -e  # Si une commande Ã©choue â” tout s'arrÃªte

echo "â¡ï¸  1. Compilation du projet Scala (.jar) avec sbt clean package..."
sbt clean package

echo "âœ… Jar compilÃ© avec succÃ¨s."

echo "â¡ï¸  2. ArrÃªt et relancement de Docker (Kafka + Spark)..."
docker-compose down
docker-compose up -d

echo "â³  Attente pour laisser dÃ©marrer Kafka, Spark Master et Worker..."
sleep 15

echo "âœ… Tous les containers sont UP."

echo "â¡ï¸  3. Lancement du Spark Producer dans le cluster Spark..."
docker exec -i $(docker ps --filter "name=spark-master" --format "{{.Names}}") spark-submit \
  --class SparkProducerBatch \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --jars /app/jars/postgresql-42.7.5.jar \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  /app/projet_spark_streaming_2.12-0.1.jar &

echo "â³  Pause pour laisser le Producer envoyer les premiers batches..."
sleep 40

echo "â¡ï¸  4. Lancement du Spark Consumer dans le cluster Spark..."
docker exec -i $(docker ps --filter "name=spark-master" --format "{{.Names}}") spark-submit \
  --class SparkConsumerStream \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --jars /app/jars/postgresql-42.7.5.jar \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  /app/projet_spark_streaming_2.12-0.1.jar

echo "âœ… TOUT tourne parfaitement dans ton cluster Spark DockerisÃ© ! ğŸš€ğŸ’¥"
