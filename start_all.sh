#!/bin/bash
set -e  # Si une commande Ã©choue â” tout s'arrÃªte

echo "â¡ï¸  1. Compilation du projet Scala (.jar) avec sbt clean package..."
sbt clean package

echo "âœ… Jar compilÃ© avec succÃ¨s."

echo "â¡ï¸  2. ArrÃªt et relancement de Docker (Kafka + Spark + Streamlit)..."
docker-compose down -v
docker-compose build
docker-compose up -d

echo "â³  Attente pour laisser dÃ©marrer Kafka, Spark, PostgreSQL..."
sleep 15

echo "âœ… Tous les containers sont UP."

echo "â¡ï¸  3. CrÃ©ation du topic Kafka 'csv-topic' s'il n'existe pas..."
docker exec -i projet_spark_streaming-kafka-1 \
  kafka-topics --create --if-not-exists \
  --bootstrap-server kafka:9092 \
  --replication-factor 1 \
  --partitions 1 \
  --topic csv-topic

echo "âœ… Topic 'csv-topic' prÃªt."

echo "â¡ï¸  4. Lancement du Spark Producer dans le cluster Spark..."
docker exec -i spark-master spark-submit \
  --class SparkProducerBatch \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --jars /app/jars/postgresql-42.7.5.jar \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  /app/projet_spark_streaming_2.12-0.1.jar &

echo "â³  Pause pour laisser le Producer envoyer les premiers batches..."
sleep 60

echo "â¡ï¸  5. Lancement du Spark Consumer dans le cluster Spark..."
docker exec -i spark-master spark-submit \
  --class SparkConsumerStream \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --jars /app/jars/postgresql-42.7.5.jar \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  /app/projet_spark_streaming_2.12-0.1.jar

echo "âœ… TOUT tourne parfaitement dans ton cluster Spark DockerisÃ© ! ğŸš€ğŸ’¥"
